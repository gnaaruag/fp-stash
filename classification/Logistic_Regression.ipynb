{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f53865b6-f8b4-419d-b8df-64efeb3030f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76ce0306-38e3-496d-9e0e-68aefd2f3b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(r\"./x_train.csv\")\n",
    "x_test = pd.read_csv(r\"./x_test.csv\")\n",
    "y_train = pd.read_csv(r\"./y_train.csv\")\n",
    "y_test = pd.read_csv(r\"./y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a08343f-3760-48fa-8e4e-fe8acfe3482a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.88      0.92        80\n",
      "        True       0.78      0.92      0.84        38\n",
      "\n",
      "    accuracy                           0.89       118\n",
      "   macro avg       0.87      0.90      0.88       118\n",
      "weighted avg       0.90      0.89      0.89       118\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn. impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the data into train and test sets\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "mdl_LR = LogisticRegression(max_iter=30000)\n",
    "mdl_LR.fit(x_train, y_train)\n",
    "y_pred_LR = mdl_LR.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41951a44-5a73-4ade-bc2d-a54e652d1ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of 'a' in notebook1: [[1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0], [True, False, True, False, True, False, False, False, True, False, True, False, True, False, True, False, False, True, True, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, True, False, True, True, False, False, False, False, True, True, False, True, False, True, False, True, False, True, False, True, False, False, False, False, False, True, True, False, False, False, False, True, True, False, True, False, True, False, False, True, False, False, False, True, False, False, True, False, True, True, False, True, False, True, False, True, False, False, True, False, False, False, True, False, False, False, False, False, True, True, False, False, False, True, False, True, False, True, False, False, True, False], [True, False, True, False, True, False, False, False, True, False, True, False, True, False, False, False, False, True, True, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, True, False, True, True, False, False, False, False, True, True, False, True, False, True, False, True, False, True, True, False, False, False, False, False, False, True, True, False, False, False, False, False, True, False, True, False, True, False, False, True, False, False, False, True, False, False, True, False, True, True, False, True, False, True, False, False, True, False, True, False, False, False, True, False, False, False, True, False, True, True, False, False, False, False, False, True, False, True, False, False, True, False], [True, False, True, False, True, False, False, False, True, False, True, False, True, False, True, False, False, True, True, False, False, False, False, False, False, False, False, True, False, False, False, False, True, True, False, False, True, False, True, True, False, False, False, False, True, True, False, True, False, True, False, True, False, True, True, True, False, False, False, False, False, True, True, False, False, False, False, True, True, False, True, False, True, False, False, True, False, False, False, True, False, False, True, False, True, True, False, True, False, True, False, True, False, False, True, False, False, False, True, False, False, False, True, False, True, True, False, False, False, True, False, True, False, False, False, False, True, False], [True, False, True, False, False, False, False, False, True, False, True, False, True, False, True, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, True, True, True, False, False, False, True, True, False, True, False, True, False, True, False, True, False, True, False, False, False, False, False, True, False, False, False, False, False, False, True, False, True, False, True, False, False, True, False, False, False, True, False, False, True, False, False, True, False, True, False, True, False, True, True, False, True, False, False, False, True, False, False, False, True, False, True, True, False, False, False, True, False, True, False, True, False, False, True, False]]\n"
     ]
    }
   ],
   "source": [
    "common_path = 'data.py'\n",
    "\n",
    "# Load the common module dynamically\n",
    "exec(open(common_path).read())\n",
    "\n",
    "# Function to update the first element\n",
    "def update_first_element(new_value):\n",
    "    global a\n",
    "    a[3] = new_value\n",
    "\n",
    "# Function to display the current value of 'a'\n",
    "def display_shared_variable():\n",
    "    print(\"Current value of 'a' in notebook1:\", a)\n",
    "\n",
    "# Update and display\n",
    "update_first_element(list(y_pred_LR))\n",
    "display_shared_variable()\n",
    "\n",
    "# Save the updated value back to common.py\n",
    "with open(common_path, 'w') as f:\n",
    "    f.write(f'a = {a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093473a6-1955-4a1c-8781-18ebde2c1d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfc9b33-e1b0-4d15-abe7-0a8ddd69cb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
