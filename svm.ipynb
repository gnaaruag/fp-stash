{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1b8bf53-4f08-4678-b569-c76234a5ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2adcca37-b354-4c20-9f40-41bee83120fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(r\"./x_train.csv\")\n",
    "x_test = pd.read_csv(r\"./x_test.csv\")\n",
    "y_train = pd.read_csv(r\"./y_train.csv\")\n",
    "y_test = pd.read_csv(r\"./y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5262273b-3d52-47f9-afb1-6bbba37005c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.88      0.92        80\n",
      "        True       0.78      0.95      0.86        38\n",
      "\n",
      "    accuracy                           0.90       118\n",
      "   macro avg       0.88      0.91      0.89       118\n",
      "weighted avg       0.91      0.90      0.90       118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn. impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "# Support Vector Machine Classifier\n",
    "svm_clf = svm.SVC(kernel=\"linear\")\n",
    "svm_clf.fit(x_train, y_train)\n",
    "y_pred=svm_clf.predict(x_test)\n",
    "svm_clf.score(x_test, y_test)*100\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0aed1e7-5a37-44bb-b245-4cf41b8e2e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of 'a' in notebook1: [[1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0], [True, False, True, False, True, False, False, False, True, False, True, False, True, False, True, False, False, True, True, False, False, False, False, False, False, False, False, True, False, False, False, False, True, True, False, False, True, False, True, True, False, False, False, False, True, True, False, True, False, True, False, True, False, True, True, True, False, False, False, False, False, True, True, False, False, False, False, True, True, False, True, False, True, False, False, True, False, False, False, True, False, False, True, False, True, True, False, True, False, True, False, True, False, False, True, False, False, False, True, False, False, False, True, False, True, True, False, False, False, True, False, True, False, True, False, False, True, False], [True, False, True, False, True, False, False, False, True, False, True, False, True, False, False, False, False, True, True, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, True, False, True, True, False, False, False, False, True, True, False, True, False, True, False, True, False, True, True, False, False, False, False, False, False, True, True, False, False, False, False, False, True, False, True, False, True, False, False, True, False, False, False, True, False, False, True, False, True, True, False, True, False, True, False, False, True, False, True, False, False, False, True, False, False, False, True, False, True, True, False, False, False, False, False, True, False, True, False, False, True, False], [True, False, True, False, True, False, False, False, True, False, True, False, True, False, True, False, False, True, True, False, False, False, False, False, False, False, False, True, False, False, False, False, True, True, False, False, True, False, True, True, False, False, False, False, True, True, False, True, False, True, False, True, False, True, True, True, False, False, False, False, False, True, True, False, False, False, False, True, True, False, True, False, True, False, False, True, False, False, False, True, False, False, True, False, True, True, False, True, False, True, False, True, False, False, True, False, False, False, True, False, False, False, True, False, True, True, False, False, False, True, False, True, False, False, False, False, True, False], [True, False, True, False, False, False, False, False, True, False, True, False, True, False, True, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, True, True, True, False, False, False, True, True, False, True, False, True, False, True, False, True, False, True, False, False, False, False, False, True, False, False, False, False, False, False, True, False, True, False, True, False, False, True, False, False, False, True, False, False, True, False, False, True, False, True, False, True, False, True, True, False, True, False, False, False, True, False, False, False, True, False, True, True, False, False, False, True, False, True, False, True, False, False, True, False]]\n"
     ]
    }
   ],
   "source": [
    "common_path = 'data.py'\n",
    "\n",
    "# Load the common module dynamically\n",
    "exec(open(common_path).read())\n",
    "\n",
    "# Function to update the first element\n",
    "def update_first_element(new_value):\n",
    "    global a\n",
    "    a[1] = new_value\n",
    "\n",
    "# Function to display the current value of 'a'\n",
    "def display_shared_variable():\n",
    "    print(\"Current value of 'a' in notebook1:\", a)\n",
    "\n",
    "# Update and display\n",
    "update_first_element(list(y_pred))\n",
    "display_shared_variable()\n",
    "\n",
    "# Save the updated value back to common.py\n",
    "with open(common_path, 'w') as f:\n",
    "    f.write(f'a = {a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0cb8d5-06bd-46b5-b375-ea3723f087ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
